<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Poisson Deterministic - hIPPYlib</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-52448613-3', 'hippylib.github.io');
            ga('send', 'pageview');
        </script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../..">hIPPYlib</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="../..">Home</a>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Tutorial <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../tutorial/">README</a>
</li>
                            
<li >
    <a href="../1_FEniCS101/">FEniCS101</a>
</li>
                            
<li class="active">
    <a href="./">Poisson Deterministic</a>
</li>
                            
<li >
    <a href="../3_SubsurfaceBayesian/">Subsurface Bayesian</a>
</li>
                            
<li >
    <a href="../4_AdvectionDiffusionBayesian/">Advection-Diffusion Bayesian</a>
</li>
                            
<li >
    <a href="../5_HessianSpectrum/">Hessian Spectrum</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">Version 1.x</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../tutorial_v1.6.0/">README</a>
</li>
            
<li >
    <a href="../../tutorials_v1.6.0/1_FEniCS101/">FEniCS101</a>
</li>
            
<li >
    <a href="../../tutorials_v1.6.0/2_PoissonDeterministic/">Poisson Deterministic</a>
</li>
            
<li >
    <a href="../../tutorials_v1.6.0/3_SubsurfaceBayesian/">Subsurface Bayesian</a>
</li>
            
<li >
    <a href="../../tutorials_v1.6.0/4_AdvectionDiffusionBayesian/">Advection-Diffusion Bayesian</a>
</li>
            
<li >
    <a href="../../tutorials_v1.6.0/5_HessianSpectrum/">Hessian Spectrum</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li >
                        <a href="../../documentation/">Documentation</a>
                    </li>
                    <li >
                        <a href="../../download/">Download</a>
                    </li>
                    <li >
                        <a href="../../research/">Research</a>
                    </li>
                    <li >
                        <a href="../../outreach/">Outreach</a>
                    </li>
                    <li >
                        <a href="../../about/">About</a>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../1_FEniCS101/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../3_SubsurfaceBayesian/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/hippylib/hippylib"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#coefficient-field-inversion-in-an-elliptic-partial-differential-equation">Coefficient field inversion in an elliptic partial differential equation</a></li>
            <li><a href="#the-variational-or-weak-form-of-the-state-equation">The variational (or weak) form of the state equation:</a></li>
            <li><a href="#gradient-evaluation">Gradient evaluation:</a></li>
            <li><a href="#hessian-action">Hessian action:</a></li>
            <li><a href="#inexact-newton-cg">Inexact Newton-CG:</a></li>
            <li><a href="#discrete-newton-system">Discrete Newton system:</a></li>
            <li><a href="#goals">Goals:</a></li>
            <li><a href="#mathematical-tools-used">Mathematical tools used:</a></li>
            <li><a href="#list-of-software-used">List of software used:</a></li>
            <li><a href="#set-up">Set up</a></li>
            <li><a href="#the-inexact-newton-cg-optimization-with-armijo-line-search">The inexact Newton-CG optimization with Armijo line search:</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="coefficient-field-inversion-in-an-elliptic-partial-differential-equation">Coefficient field inversion in an elliptic partial differential equation</h1>
<p>We consider the estimation of a coefficient in an elliptic partial
differential equation as a model problem. Depending on the
interpretation of the unknowns and the type of measurements, this
model problem arises, for instance, in inversion for groundwater flow
or heat conductivity.  It can also be interpreted as finding a
membrane with a certain spatially varying stiffness. Let
<script type="math/tex">\Omega\subset\mathbb{R}^n</script>, <script type="math/tex">n\in\{1,2,3\}</script> be an open, bounded
domain and consider the following problem:</p>
<p>
<script type="math/tex; mode=display">
\min_{m} J(m):=\frac{1}{2}\int_\Omega (u-u_d)^2\, dx + \frac{\gamma}{2}\int_\Omega|\nabla m|^2\,dx,
</script>
</p>
<p>where <script type="math/tex">u</script> is the solution of</p>
<p>
<script type="math/tex; mode=display">
\begin{split}
\quad -\nabla\cdot(\exp(m)\nabla u) &= f \text{ in }\Omega,\\
u &= 0 \text{ on }\partial\Omega.
\end{split}
</script>
</p>
<p>Here <script type="math/tex">m\in U_{ad}:=\{m\in H^1(\Omega) \bigcap L^{\infty}(\Omega)\}</script> the unknown coefficient field, <script type="math/tex">u_d</script> denotes (possibly noisy) data, <script type="math/tex">f\in H^{-1}(\Omega)</script> a given force, and <script type="math/tex">\gamma\ge 0</script> the regularization parameter.</p>
<h3 id="the-variational-or-weak-form-of-the-state-equation">The variational (or weak) form of the state equation:</h3>
<p>Find <script type="math/tex">u\in H_0^1(\Omega)</script> such that </p>
<p>
<script type="math/tex; mode=display">(\exp(m)\nabla u,\nabla v) - (f,v) = 0, \text{ for all } v\in H_0^1(\Omega),</script>
</p>
<p>where <script type="math/tex">H_0^1(\Omega)</script> is the space of functions vanishing on <script type="math/tex">\partial\Omega</script> with square integrable derivatives. Here, <script type="math/tex">(\cdot\,,\cdot)</script> denotes the <script type="math/tex">L^2</script>-inner product, i.e, for scalar functions <script type="math/tex">u,v \in L^2(\Omega)</script>  we denote </p>
<p>
<script type="math/tex; mode=display">(u,v) := \int_\Omega u(x) v(x) \,dx.</script>
</p>
<h3 id="gradient-evaluation">Gradient evaluation:</h3>
<p>The Lagrangian functional <script type="math/tex">\mathscr{L}:H_0^1(\Omega)\times H^1(\Omega)\times H_0^1(\Omega)\rightarrow \mathbb{R}</script> is given by</p>
<p>
<script type="math/tex; mode=display">
\mathscr{L}(u,m,p):= \frac{1}{2}(u-u_d,u-u_d) +
\frac{\gamma}{2}(\nabla m, \nabla m) +  (\exp(m)\nabla u,\nabla p) - (f,p).
</script>
</p>
<p>Then the gradient of the cost functional <script type="math/tex">\mathcal{J}(m)</script> with respect to the parameter <script type="math/tex">m</script> is</p>
<p>
<script type="math/tex; mode=display">
    \mathcal{G}(m)(\tilde m) := \gamma(\nabla m, \nabla \tilde{m}) +
     (\tilde{m}\exp(m)\nabla u, \nabla p) \quad \forall \tilde{m} \in H^1(\Omega),
</script>
</p>
<p>where <script type="math/tex">u \in H_0^1(\Omega)</script> is the solution of the forward problem,</p>
<p>
<script type="math/tex; mode=display"> \mathscr{L}_p(u,m,p)(\tilde{p})  := (\exp(m)\nabla u, \nabla \tilde{p}) - (f,\tilde{p}) = 0
\quad \forall \tilde{p} \in H_0^1(\Omega), </script>
</p>
<p>and <script type="math/tex">p \in H_0^1(\Omega)</script> is the solution of the adjoint problem,</p>
<p>
<script type="math/tex; mode=display"> \mathscr{L}_u(u,m,p)(\tilde{u}) := (\exp(m)\nabla p, \nabla \tilde{u}) + (u-u_d,\tilde{u}) = 0
\quad \forall \tilde{u} \in H_0^1(\Omega).</script>
</p>
<h3 id="hessian-action">Hessian action:</h3>
<p>To evaluate the action <script type="math/tex">\mathcal{H}(m)(\hat{m})</script> of the Hessian is a given direction <script type="math/tex">\hat{m}</script> , we consider variations of the meta-Lagrangian functional</p>
<p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathscr{L}^H(u,m,p; \hat{u}, \hat{m}, \hat{p}) := & {} & {} \\
{} & \gamma(\nabla m, \nabla \tilde{m}) + (\tilde{m}\exp(m)\nabla u, \nabla p) & \text{gradient}\\
{} & + (\exp(m)\nabla u, \nabla \hat{p}) - (f,\hat{p}) & \text{forward eq}\\
{} & + (\exp(m)\nabla p, \nabla \hat{u}) + (u-u_d,\hat{u}) & \text{adjoint eq}.
\end{aligned}
</script>
</p>
<p>Then action of the Hessian is a given direction <script type="math/tex">\hat{m}</script> is</p>
<p>
<script type="math/tex; mode=display">
\begin{aligned}
(\tilde{m}, \mathcal{H}(m)(\hat{m}) ) & := \mathscr{L}^H_m(u,m,p; \hat{u}, \hat{m}, \hat{p})(\tilde{m}) \\
{} & =
(\tilde{m} \exp(m) \nabla \hat{u}, \nabla{p}) + \gamma (\nabla \hat{m}, \nabla \tilde{m}) + (\tilde{m} \hat{m} \exp(m)\nabla u, \nabla p) + (\tilde{m}\exp(m) \nabla u, \nabla \hat{p}) \quad \forall \tilde{m} \in H^1(\Omega),
\end{aligned}
</script>
</p>
<p>where </p>
<ul>
<li>
<p>
<script type="math/tex">u\in H^1_0(\Omega)</script> and <script type="math/tex">p \in H^1_0(\Omega)</script> are the solution of the forward and adjoint problem, respectively;</p>
</li>
<li>
<p>
<script type="math/tex">\hat{u} \in H^1_0(\Omega)</script> is the solution of the incremental forward problem,</p>
</li>
</ul>
<p>
<script type="math/tex; mode=display">
\mathscr{L}^H_p(u,m,p; \hat{u}, \hat{m}, \hat{p})(\tilde{p}) := (\exp(m) \nabla \hat{u}, \nabla \tilde{p}) + (\hat{m} \exp(m) \nabla u, \nabla \tilde p) = 0 \quad \forall \tilde{p} \in H_0^1(\Omega);
</script>
</p>
<ul>
<li>and <script type="math/tex">\hat{p} \in H^1_0(\Omega)</script> is the solution of the incremental adjoint problem,
<script type="math/tex; mode=display">
\mathscr{L}^H_u(u,m,p; \hat{u}, \hat{m}, \hat{p})(\tilde{u}) := (\hat{u}, \tilde{u}) + (\hat{m} \exp(m)\nabla p, \nabla \tilde{u}) + (\exp(m) \nabla \tilde u, \nabla \hat{p}) = 0 \quad \forall \tilde{u} \in H_0^1(\Omega).
</script>
</li>
</ul>
<h3 id="inexact-newton-cg">Inexact Newton-CG:</h3>
<p>Written in abstract form, the Newton Method computes an update direction <script type="math/tex">\hat{m}_k</script> by solving the linear system </p>
<p>
<script type="math/tex; mode=display">
(\tilde{m}, \mathcal{H}(m_k)(\hat{m}_k) ) = -\mathcal{G}(m_k)(\tilde m) \quad \forall \tilde{m} \in H^1(\Omega),
</script>
</p>
<p>where the evaluation of the gradient <script type="math/tex">\mathcal{G}(m_k)</script> involve the solution <script type="math/tex">u_k</script> and <script type="math/tex">p_k</script> of the forward and adjoint problem (respectively) for <script type="math/tex">m = m_k</script>.
Similarly, the Hessian action <script type="math/tex">\mathcal{H}(m_k)(\hat{m}_k)</script> requires to additional solve the incremental forward and adjoint problems.</p>
<h3 id="discrete-newton-system">Discrete Newton system:</h3>
<p>
<script type="math/tex">
\def\tu{\tilde u}
\def\tm{\tilde m}
\def\tp{\tilde p}
\def\hu{\hat u}
\def\hp{\hat p}
\def\hm{\hat m}
</script>
</p>
<p>
<script type="math/tex">
\def\bu{{\bf u}}
\def\bm{{\bf m}}
\def\bp{{\bf p}}
\def\btu{{\bf \tilde u}}
\def\btm{{\bf \tilde m}}
\def\btp{{\bf \tilde p}}
\def\bhu{{\bf \hat u}}
\def\bhm{{\bf \hat m}}
\def\bhp{{\bf \hat p}}
\def\bg{{\bf g}}
</script>
</p>
<p>
<script type="math/tex">
\def\bA{{\bf A}}
\def\bC{{\bf C}}
\def\bH{{\bf H}}
\def\bR{{\bf R}}
\def\bW{{\bf W}}
</script>
</p>
<p>Let us denote the vectors corresponding to the discretization of the functions <script type="math/tex">u_k, m_k, p_k</script> by <script type="math/tex">\bu_k, \bm_k, \bp_k</script> and of the functions <script type="math/tex">\hu_k, \hm_k, \hp_k</script> by <script type="math/tex">\bhu_k, \bhm_k,\bhp_k</script>.</p>
<p>Then, the discretization of the above system is given by the following symmetric linear system:</p>
<p>
<script type="math/tex; mode=display">
  \bH_k \, \bhm_k = -\bg_k.
</script>
</p>
<p>The gradient <script type="math/tex">\bg_k</script> is computed using the following three steps</p>
<ul>
<li>Given <script type="math/tex">\bm_k</script> we solve the forward problem</li>
</ul>
<p>
<script type="math/tex; mode=display"> \bA_k \bu_k = {\bf f}, </script>
</p>
<p>where <script type="math/tex">\bA_k \bu_k</script> stems from the discretization <script type="math/tex">(\exp(m_k)\nabla u_k, \nabla \tilde{p})</script>, and <script type="math/tex">{\bf f}</script> stands for the discretization of the right hand side <script type="math/tex">f</script>.</p>
<ul>
<li>Given <script type="math/tex">\bm_k</script> and <script type="math/tex">\bu_k</script> solve the adjoint problem</li>
</ul>
<p>
<script type="math/tex; mode=display"> \bA_k^T \bp_k = - \bW_{\scriptsize\mbox{uu}}\,(\bu_k-\bu_d) </script>
</p>
<p>where <script type="math/tex">\bA_k^T \bp_k</script> stems from the discretization of <script type="math/tex">(\exp(m_k)\nabla \tilde{u}, \nabla p_k)</script>, <script type="math/tex">\bW_{\scriptsize\mbox{uu}}</script> is the mass matrix corresponding to the <script type="math/tex">L^2</script> inner product in the state space, and <script type="math/tex">\bu_d</script> stems from the data.</p>
<ul>
<li>Define the gradient </li>
</ul>
<p>
<script type="math/tex; mode=display"> \bg_k = \bR \bm_k + \bC_k^T \bp_k, </script>
</p>
<p>where <script type="math/tex">\bR</script> is the matrix stemming from discretization of the regularization operator <script type="math/tex">\gamma ( \nabla \hat{m}, \nabla \tilde{m})</script>, and <script type="math/tex">\bC_k</script> stems from discretization of the term <script type="math/tex">(\tilde{m}\exp(m_k)\nabla u_k, \nabla p_k)</script>.</p>
<p>Similarly the action of the Hessian <script type="math/tex">\bH_k \, \bhm_k</script> in a direction <script type="math/tex">\bhm_k</script> (by using the CG algorithm we only need the action of <script type="math/tex">\bH_k</script> to solve the Newton step) is given by</p>
<ul>
<li>Solve the incremental forward problem</li>
</ul>
<p>
<script type="math/tex; mode=display"> \bA_k \bhu_k = -\bC_k \bhm_k, </script>
</p>
<p>where <script type="math/tex">\bC_k \bm_k</script> stems from discretization of <script type="math/tex">(\hat{m} \exp(m_k) \nabla u_k, \nabla \tilde p)</script>.</p>
<ul>
<li>Solve the incremental adjoint problem</li>
</ul>
<p>
<script type="math/tex; mode=display"> \bA_k^T \bhp_k = -(\bW_{\scriptsize\mbox{uu}} \bhu_k + \bW_{\scriptsize\mbox{um}}\,\bhm_k),</script>
</p>
<p>where <script type="math/tex">\bW_{\scriptsize\mbox{um}}\,\bhm_k</script> stems for the discretization of <script type="math/tex">(\hat{m}_k \exp(m_k)\nabla p_k, \nabla \tilde{u})</script>.</p>
<ul>
<li>Define the Hessian action</li>
</ul>
<p>
<script type="math/tex; mode=display">
  \bH_k \, \bhm = \underbrace{(\bR + \bW_{\scriptsize\mbox{mm}})}_{\text{Hessian of the regularization}} \bhm +
    \underbrace{(\bC_k^{T}\bA_k^{-T} (\bW_{\scriptsize\mbox{uu}}
    \bA_k^{-1} \bC_k - \bW_{\scriptsize\mbox{um}}) -
    \bW_{\scriptsize\mbox{mu}} \bA_k^{-1}
    \bC_k)}_{\text{Hessian of the data misfit}}\;\bhm.
</script>
</p>
<h3 id="goals">Goals:</h3>
<p>By the end of this notebook, you should be able to:</p>
<ul>
<li>solve the forward and adjoint Poisson equations</li>
<li>understand the inverse method framework</li>
<li>visualise and understand the results</li>
<li>modify the problem and code</li>
</ul>
<h3 id="mathematical-tools-used">Mathematical tools used:</h3>
<ul>
<li>Finite element method</li>
<li>Derivation of gradiant and Hessian via the adjoint method</li>
<li>inexact Newton-CG</li>
<li>Armijo line search</li>
</ul>
<h3 id="list-of-software-used">List of software used:</h3>
<ul>
<li><a href="http://fenicsproject.org/">FEniCS</a>, a parallel finite element element library for the discretization of partial differential equations</li>
<li><a href="http://www.mcs.anl.gov/petsc/">PETSc</a>, for scalable and efficient linear algebra operations and solvers</li>
<li><a href="http://matplotlib.org/">Matplotlib</a>, a python package used for plotting the results</li>
</ul>
<h2 id="set-up">Set up</h2>
<h3 id="import-dependencies">Import dependencies</h3>
<pre><code class="python">from __future__ import absolute_import, division, print_function

from dolfin import *

import sys
import os
sys.path.append( os.environ.get('HIPPYLIB_BASE_DIR', &quot;../&quot;) )
from hippylib import *

import logging

import matplotlib.pyplot as plt
%matplotlib inline

logging.getLogger('FFC').setLevel(logging.WARNING)
logging.getLogger('UFL').setLevel(logging.WARNING)
set_log_active(False)
</code></pre>

<h3 id="model-set-up">Model set up:</h3>
<p>As in the introduction, the first thing we need to do is set up the numerical model.  In this cell, we set the mesh, the finite element functions <script type="math/tex">u, p, g</script> corresponding to state, adjoint and coefficient/gradient variables, and the corresponding test functions and the parameters for the optimization.</p>
<pre><code class="python"># create mesh and define function spaces
nx = 64
ny = 64
mesh = UnitSquareMesh(nx, ny)
Vm = FunctionSpace(mesh, 'Lagrange', 1)
Vu = FunctionSpace(mesh, 'Lagrange', 2)

# The true and inverted parameter
mtrue = interpolate(Expression('log(2 + 7*(pow(pow(x[0] - 0.5,2) + pow(x[1] - 0.5,2),0.5) &gt; 0.2))', degree=5),Vm)
m = interpolate(Expression(&quot;log(2.0)&quot;, degree=1),Vm)

# define function for state and adjoint
u = Function(Vu)
p = Function(Vu)

# define Trial and Test Functions
u_trial, p_trial, m_trial = TrialFunction(Vu), TrialFunction(Vu), TrialFunction(Vm)
u_test, p_test, m_test = TestFunction(Vu), TestFunction(Vu), TestFunction(Vm)

# initialize input functions
f = Constant(&quot;1.0&quot;)
u0 = Constant(&quot;0.0&quot;)

# plot
plt.figure(figsize=(15,5))
nb.plot(mesh,subplot_loc=121, mytitle=&quot;Mesh&quot;, show_axis='on')
nb.plot(mtrue,subplot_loc=122, mytitle=&quot;True parameter field&quot;)
plt.show()
</code></pre>

<p><img alt="png" src="../2_PoissonDeterministic_files/2_PoissonDeterministic_4_0.png" /></p>
<pre><code class="python"># set up dirichlet boundary conditions
def boundary(x,on_boundary):
    return on_boundary

bc_state = DirichletBC(Vu, u0, boundary)
bc_adj = DirichletBC(Vu, Constant(0.), boundary)
</code></pre>

<h3 id="set-up-synthetic-observations">Set up synthetic observations:</h3>
<ul>
<li>Propose a coefficient field <script type="math/tex">m_{\rm true}</script> shown above</li>
<li>
<p>The weak form of the pde: 
    Find <script type="math/tex">u\in H_0^1(\Omega)</script> such that <script type="math/tex">\underbrace{(\exp(m_{\rm true})\nabla u,\nabla v)}_{\; := \; a_{pde}} - \underbrace{(f,v)}_{\; := \;L_{pde}} = 0, \text{ for all } v\in H_0^1(\Omega)</script>.</p>
</li>
<li>
<p>Perturb the solution: <script type="math/tex">u = u + \eta</script>, where <script type="math/tex">\eta \sim \mathcal{N}(0, \sigma)</script>
</p>
</li>
</ul>
<pre><code class="python"># noise level
noise_level = 0.05

# weak form for setting up the synthetic observations
a_goal = inner(exp(mtrue) * nabla_grad(u_trial), nabla_grad(u_test)) * dx
L_goal = f * u_test * dx

# solve the forward/state problem to generate synthetic observations
goal_A, goal_b = assemble_system(a_goal, L_goal, bc_state)

utrue = Function(Vu)
solve(goal_A, utrue.vector(), goal_b)

ud = Function(Vu)
ud.assign(utrue)

# perturb state solution and create synthetic measurements ud
# ud = u + ||u||/SNR * random.normal
MAX = ud.vector().norm(&quot;linf&quot;)
noise = Vector()
goal_A.init_vector(noise,1)
parRandom.normal(noise_level * MAX, noise)
bc_adj.apply(noise)

ud.vector().axpy(1., noise)

# plot
nb.multi1_plot([utrue, ud], [&quot;State solution with mtrue&quot;, &quot;Synthetic observations&quot;])
plt.show()
</code></pre>

<p><img alt="png" src="../2_PoissonDeterministic_files/2_PoissonDeterministic_7_0.png" /></p>
<h3 id="the-cost-function-evaluation">The cost function evaluation:</h3>
<p>
<script type="math/tex; mode=display">
J(m):=\underbrace{\frac{1}{2}\int_\Omega (u-u_d)^2\, dx}_{\text{misfit} } + \underbrace{\frac{\gamma}{2}\int_\Omega|\nabla m|^2\,dx}_{\text{reg}}
</script>
</p>
<p>In the code below, <script type="math/tex">\bW</script> and <script type="math/tex">\bR</script> are symmetric positive definite matrices that stem from finite element discretization of the misfit and regularization component of the cost functional, respectively.</p>
<pre><code class="python"># regularization parameter
gamma = 1e-8

# weak for for setting up the misfit and regularization compoment of the cost
W_equ   = inner(u_trial, u_test) * dx
R_equ   = gamma * inner(nabla_grad(m_trial), nabla_grad(m_test)) * dx

W = assemble(W_equ)
R = assemble(R_equ)

# refine cost function
def cost(u, ud, m, W, R):
    diff = u.vector() - ud.vector()
    reg = 0.5 * m.vector().inner(R*m.vector() ) 
    misfit = 0.5 * diff.inner(W * diff)
    return [reg + misfit, misfit, reg]
</code></pre>

<h3 id="setting-up-the-state-equations-right-hand-side-for-the-adjoint-and-the-necessary-matrices">Setting up the state equations, right hand side for the adjoint and the necessary matrices:</h3>
<pre><code class="python"># weak form for setting up the state equation
a_state = inner(exp(m) * nabla_grad(u_trial), nabla_grad(u_test)) * dx
L_state = f * u_test * dx

# weak form for setting up the adjoint equation
a_adj = inner(exp(m) * nabla_grad(p_trial), nabla_grad(p_test)) * dx
L_adj = -inner(u - ud, p_test) * dx

# weak form for setting up matrices
Wum_equ = inner(exp(m) * m_trial * nabla_grad(p_test), nabla_grad(p)) * dx
C_equ   = inner(exp(m) * m_trial * nabla_grad(u), nabla_grad(u_test)) * dx
Wmm_equ = inner(exp(m) * m_trial * m_test *  nabla_grad(u),  nabla_grad(p)) * dx

M_equ   = inner(m_trial, m_test) * dx

# assemble matrix M
M = assemble(M_equ)
</code></pre>

<h3 id="initial-guess">Initial guess</h3>
<p>We solve the state equation and compute the cost functional for the initial guess of the parameter <code>a_ini</code></p>
<pre><code class="python"># solve state equation
state_A, state_b = assemble_system (a_state, L_state, bc_state)
solve (state_A, u.vector(), state_b)

# evaluate cost
[cost_old, misfit_old, reg_old] = cost(u, ud, m, W, R)

# plot
plt.figure(figsize=(15,5))
nb.plot(m,subplot_loc=121, mytitle=&quot;m_ini&quot;, vmin=mtrue.vector().min(), vmax=mtrue.vector().max())
nb.plot(u,subplot_loc=122, mytitle=&quot;u(m_ini)&quot;)
plt.show()
</code></pre>

<p><img alt="png" src="../2_PoissonDeterministic_files/2_PoissonDeterministic_13_0.png" /></p>
<h3 id="the-reduced-hessian-apply-to-a-vector-bhm">The reduced Hessian apply to a vector <script type="math/tex">\bhm</script>:</h3>
<p>Here we describe how to apply the reduced Hessian operator to a vector <script type="math/tex">\bhm</script>. For an opportune choice of the regularization, the reduced Hessian operator evaluated in a neighborhood of the solution is positive define, whereas far from the solution the reduced Hessian may be indefinite. On the constrary, the Gauss-Newton approximation of the Hessian is always positive defined.</p>
<p>For this reason, it is beneficial to perform a few initial Gauss-Newton steps (5 in this particular example) to accelerate the convergence of the inexact Newton-CG algorithm.</p>
<p>The Hessian apply reads:
<script type="math/tex; mode=display">
\begin{align}
\bhu &= -\bA^{-1} \bC \bhm\, & \text{linearized forward}\\
\bhp &= -\bA^{-T} (\bW_{\scriptsize\mbox{uu}} \bhu +
\bW_{\scriptsize\mbox{um}}\,\bhm) & \text{adjoint}\\
\bH \bhm &= (\bR + \bW_{\scriptsize\mbox{mm}})\bhm + \bC^T \bhp + \bW_{\scriptsize\mbox{mu}} \bhu.
\end{align}
</script>
</p>
<p>The Gauss-Newton Hessian apply is obtained by dropping the second derivatives operators <script type="math/tex">\bW_{\scriptsize\mbox{um}}\,\bhm</script>, <script type="math/tex">\bW_{\scriptsize\mbox{mm}}\bf \bhm</script>, and <script type="math/tex">\bW_{\scriptsize\mbox{mu}} \bhu</script>:
<script type="math/tex; mode=display">
\begin{align}
\bhu &= -\bA^{-1} \bC \bf \bhm\, & \text{linearized forward}\\
\bhp &= -\bA^{-T} \bW_{\scriptsize\mbox{uu}} \bhu & \text{adjoint}\\
\bH_{\rm GN} \bhm &= \bR \bhm + \bC^T \bhp.
\end{align}
</script>
</p>
<pre><code class="python"># Class HessianOperator to perform Hessian apply to a vector
class HessianOperator():
    cgiter = 0
    def __init__(self, R, Wmm, C, A, adj_A, W, Wum, gauss_newton_approx=False):
        self.R = R
        self.Wmm = Wmm
        self.C = C
        self.A = A
        self.adj_A = adj_A
        self.W = W
        self.Wum = Wum
        self.gauss_newton_approx = gauss_newton_approx

        # incremental state
        self.du = Vector()
        self.A.init_vector(self.du,0)

        #incremental adjoint
        self.dp = Vector()
        self.adj_A.init_vector(self.dp,0)

        # auxiliary vectors
        self.CT_dp = Vector()
        self.C.init_vector(self.CT_dp, 1)
        self.Wum_du = Vector()
        self.Wum.init_vector(self.Wum_du, 1)

    def init_vector(self, v, dim):
        self.R.init_vector(v,dim)

    # Hessian performed on v, output as generic vector y
    def mult(self, v, y):
        self.cgiter += 1
        y.zero()
        if self.gauss_newton_approx:
            self.mult_GaussNewton(v,y)
        else:
            self.mult_Newton(v,y)

    # define (Gauss-Newton) Hessian apply H * v
    def mult_GaussNewton(self, v, y):

        #incremental forward
        rhs = -(self.C * v)
        bc_adj.apply(rhs)
        solve (self.A, self.du, rhs)

        #incremental adjoint
        rhs = - (self.W * self.du)
        bc_adj.apply(rhs)
        solve (self.adj_A, self.dp, rhs)

        # Reg/Prior term
        self.R.mult(v,y)

        # Misfit term
        self.C.transpmult(self.dp, self.CT_dp)
        y.axpy(1, self.CT_dp)

    # define (Newton) Hessian apply H * v
    def mult_Newton(self, v, y):

        #incremental forward
        rhs = -(self.C * v)
        bc_adj.apply(rhs)
        solve (self.A, self.du, rhs)

        #incremental adjoint
        rhs = -(self.W * self.du) -  self.Wum * v
        bc_adj.apply(rhs)
        solve (self.adj_A, self.dp, rhs)

        #Reg/Prior term
        self.R.mult(v,y)
        y.axpy(1., self.Wmm*v)

        #Misfit term
        self.C.transpmult(self.dp, self.CT_dp)
        y.axpy(1., self.CT_dp)
        self.Wum.transpmult(self.du, self.Wum_du)
        y.axpy(1., self.Wum_du)
</code></pre>

<h2 id="the-inexact-newton-cg-optimization-with-armijo-line-search">The inexact Newton-CG optimization with Armijo line search:</h2>
<p>We solve the constrained optimization problem using the inexact Newton-CG method with Armijo line search.</p>
<p>The stopping criterion is based on a relative reduction of the norm of the gradient (i.e. <script type="math/tex">\frac{\|g_{n}\|}{\|g_{0}\|} \leq \tau</script>).</p>
<p>First, we compute the gradient by solving the state and adjoint equation for the current parameter <script type="math/tex">m</script>, and then substituing the current state <script type="math/tex">u</script>, parameter <script type="math/tex">m</script> and adjoint <script type="math/tex">p</script> variables in the weak form expression of the gradient:
<script type="math/tex; mode=display"> (g, \tilde{m}) = \gamma(\nabla m, \nabla \tilde{m}) +(\tilde{m}\nabla u, \nabla p).</script>
</p>
<p>Then, we compute the Newton direction <script type="math/tex">\hat m</script> by iteratively solving <script type="math/tex">\mathcal{H} {\hat m} = -g</script>.
The Newton system is solved inexactly by early termination of conjugate gradient iterations via Eisenstat–Walker (to prevent oversolving) and Steihaug  (to avoid negative curvature) criteria.</p>
<p>Finally, the Armijo line search uses backtracking to find <script type="math/tex">\alpha</script> such that a sufficient reduction in the cost functional is achieved.
More specifically, we use backtracking to find <script type="math/tex">\alpha</script> such that:
<script type="math/tex; mode=display">J( m + \alpha \hat m ) \leq J(m) + \alpha c_{\rm armijo} (\hat m,g). </script>
</p>
<pre><code class="python"># define parameters for the optimization
tol = 1e-8
c = 1e-4
maxiter = 12
plot_on = False

# initialize iter counters
iter = 1
total_cg_iter = 0
converged = False

# initializations
g, m_delta = Vector(), Vector()
R.init_vector(m_delta,0)
R.init_vector(g,0)

m_prev = Function(Vm)

print (&quot;Nit   CGit   cost          misfit        reg           sqrt(-G*D)    ||grad||       alpha  tolcg&quot;)

while iter &lt;  maxiter and not converged:

    # assemble matrix C
    C =  assemble(C_equ)

    # solve the adoint problem
    adjoint_A, adjoint_RHS = assemble_system(a_adj, L_adj, bc_adj)
    solve(adjoint_A, p.vector(), adjoint_RHS)

    # assemble W_ua and R
    Wum = assemble (Wum_equ)
    Wmm = assemble (Wmm_equ)

    # evaluate the  gradient
    CT_p = Vector()
    C.init_vector(CT_p,1)
    C.transpmult(p.vector(), CT_p)
    MG = CT_p + R * m.vector()
    solve(M, g, MG)

    # calculate the norm of the gradient
    grad2 = g.inner(MG)
    gradnorm = sqrt(grad2)

    # set the CG tolerance (use Eisenstat–Walker termination criterion)
    if iter == 1:
        gradnorm_ini = gradnorm
    tolcg = min(0.5, sqrt(gradnorm/gradnorm_ini))

    # define the Hessian apply operator (with preconditioner)
    Hess_Apply = HessianOperator(R, Wmm, C, state_A, adjoint_A, W, Wum, gauss_newton_approx=(iter&lt;6) )
    P = R + gamma * M
    Psolver = PETScKrylovSolver(&quot;cg&quot;, amg_method())
    Psolver.set_operator(P)

    solver = CGSolverSteihaug()
    solver.set_operator(Hess_Apply)
    solver.set_preconditioner(Psolver)
    solver.parameters[&quot;rel_tolerance&quot;] = tolcg
    solver.parameters[&quot;zero_initial_guess&quot;] = True
    solver.parameters[&quot;print_level&quot;] = -1

    # solve the Newton system H a_delta = - MG
    solver.solve(m_delta, -MG)
    total_cg_iter += Hess_Apply.cgiter

    # linesearch
    alpha = 1
    descent = 0
    no_backtrack = 0
    m_prev.assign(m)
    while descent == 0 and no_backtrack &lt; 10:
        m.vector().axpy(alpha, m_delta )

        # solve the state/forward problem
        state_A, state_b = assemble_system(a_state, L_state, bc_state)
        solve(state_A, u.vector(), state_b)

        # evaluate cost
        [cost_new, misfit_new, reg_new] = cost(u, ud, m, W, R)

        # check if Armijo conditions are satisfied
        if cost_new &lt; cost_old + alpha * c * MG.inner(m_delta):
            cost_old = cost_new
            descent = 1
        else:
            no_backtrack += 1
            alpha *= 0.5
            m.assign(m_prev)  # reset a

    # calculate sqrt(-G * D)
    graddir = sqrt(- MG.inner(m_delta) )

    sp = &quot;&quot;
    print( &quot;%2d %2s %2d %3s %8.5e %1s %8.5e %1s %8.5e %1s %8.5e %1s %8.5e %1s %5.2f %1s %5.3e&quot; % \
        (iter, sp, Hess_Apply.cgiter, sp, cost_new, sp, misfit_new, sp, reg_new, sp, \
         graddir, sp, gradnorm, sp, alpha, sp, tolcg) )

    if plot_on:
        nb.multi1_plot([m,u,p], [&quot;m&quot;,&quot;u&quot;,&quot;p&quot;], same_colorbar=False)
        plt.show()

    # check for convergence
    if gradnorm &lt; tol and iter &gt; 1:
        converged = True
        print( &quot;Newton's method converged in &quot;,iter,&quot;  iterations&quot;)
        print( &quot;Total number of CG iterations: &quot;, total_cg_iter)

    iter += 1

if not converged:
    print( &quot;Newton's method did not converge in &quot;, maxiter, &quot; iterations&quot;)
</code></pre>

<pre><code>Nit   CGit   cost          misfit        reg           sqrt(-G*D)    ||grad||       alpha  tolcg
 1     1     1.12816e-05   1.12816e-05   1.34063e-11   1.56576e-02   3.79516e-04    1.00   5.000e-01
 2     1     7.82345e-07   7.82308e-07   3.68084e-11   4.68471e-03   5.35131e-05    1.00   3.755e-01
 3     1     3.12377e-07   3.12328e-07   4.91890e-11   9.72528e-04   7.14277e-06    1.00   1.372e-01
 4     6     1.91931e-07   1.61602e-07   3.03286e-08   4.54949e-04   1.00710e-06    1.00   5.151e-02
 5     1     1.86508e-07   1.56163e-07   3.03445e-08   1.04154e-04   6.18455e-07    1.00   4.037e-02
 6    12     1.80489e-07   1.37364e-07   4.31244e-08   1.11510e-04   2.15007e-07    1.00   2.380e-02
 7     5     1.80421e-07   1.38523e-07   4.18984e-08   1.15380e-05   3.88978e-08    1.00   1.012e-02
 8    15     1.80420e-07   1.38637e-07   4.17830e-08   1.64609e-06   3.27512e-09    1.00   2.938e-03
Newton's method converged in  8   iterations
Total number of CG iterations:  42
</code></pre>
<pre><code class="python">nb.multi1_plot([mtrue, m], [&quot;mtrue&quot;, &quot;m&quot;])
nb.multi1_plot([u,p], [&quot;u&quot;,&quot;p&quot;], same_colorbar=False)
plt.show()
</code></pre>

<p><img alt="png" src="../2_PoissonDeterministic_files/2_PoissonDeterministic_18_0.png" /></p>
<p><img alt="png" src="../2_PoissonDeterministic_files/2_PoissonDeterministic_18_1.png" /></p>
<p>Copyright (c) 2016-2018, The University of Texas at Austin &amp; University of California, Merced.<br>
All Rights reserved.<br>
See file COPYRIGHT for details.</p>
<p>This file is part of the hIPPYlib library. For more information and source code
availability see https://hippylib.github.io.</p>
<p>hIPPYlib is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License (as published by the Free Software Foundation) version 2.0 dated June 1991.</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2016-2018 The University of Texas at Austin, University of California Merced. <br> This material is based on work partially supported by the National Science Foundation under Grants No ACI-1550593, ACI-1550547.</p>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../..';</script>
        <script src="../../js/base.js"></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="../../search/require.js"></script>
        <script src="../../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
